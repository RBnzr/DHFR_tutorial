data("dfhr")
data(dfhr)
library(datasets)
library(tidyverse)
data(dfhr)
data("dfhr")
data(dhfr)
dfhr <- read.csv(text = getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv") )
dfhr <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv") )
dfhr <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
dfhr <- getURL("http://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
install.packages("rcurl")
library(RCurl)
dfhr <- getURL("http://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
library(curl)
dfhr <- getURL("http://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
dfhr <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
x <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
x <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv")
x <- read.csv(getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
library(XML)
library(RCurl)
install.packages(XML)
install.packages("XML")
install.packages("RCurl")
library(XML)
library(RCurl)
x <- read.csv(getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
x <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv"))
x <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv")
x <- getURL("dhfr.csv")
remove(x)
x <- getURL("https://raw.githubusercontent.com/dataprofessor/data/master/dhfr.csv")
#Load Dataset
dhfr <- read_csv("dhfr_data.csv")
summary(dfhr)
summary(dfhr)
View(dfhr)
View(dhfr)
summary(dhfr)
summary(dhfr$Y)
dhfr$Y <- as.factor(dhfr$Y)
summary(dhfr)
summary(dhfr$Y)
# check If NA values exist
sum(is.na(dhfr))
library(skimr)
skim(dhfr)
dhfr %>%
group_by(Y) %>%
skim()
skimed_data <-dhfr %>%
group_by(Y) %>%
skim()
plot(dhfr)
plot(dhfr$moe2D_vsa_base, dhfr$Y, xlab = "VSA Base", ylab = "Biological Activity (Y)" )
plot(dhfr$moe2D_zagreb, dhfr$Y, xlab = "2D Zagreb", ylab = "Biological Activity (Y)", col = dhfr$Y )
plot(dhfr$moe2D_zagreb, dhfr$moe2D_weinerPol, xlab = "2D Zagreb", ylab = "2D WeinerPol", col = dhfr$Y )
#histogram
hist(dhfr$Y)
#histogram
hist(dhfr$moe2D_zagreb)
hist(dhfr$moe2D_zagreb, col = dhfr$Y)
library(caret)
featurePlot(x = dhfr[,2:5],
y = dhfr$Y,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = dhfr[,2:25],
y = dhfr$Y,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = dhfr[,2:21],
y = dhfr$Y,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
# set seed
set.seed(100)
trainingIndex <- createDataPartition(dhfr$Y, p = 0.8, list = FALSE)
trainingSet <- dhfr[trainingIndex,]
testingSet <- dhfr[-trainingIndex,]
library(ggplot2)
skimed_data <- ggplot() +
geom_bar()
skimed_data <-dhfr %>%
group_by(Y) %>%
skim()
barplot <- skimmed_data %>%
ggplot() +
geom_bar()
barplot <- skimmd_data %>%
ggplot() +
geom_bar()
barplot <- skimed_data %>%
ggplot() +
geom_bar()
skimed_data %>%
ggplot() +
geom_bar()
skimed_data %>%
ggplot(aes(Y)) +
geom_bar()
dhfr %>%
ggplot(aes(Y)) +
geom_bar()
dhfr %>%
ggplot(aes(Y)) +
geom_bar() +
facet_wrap(~variable, scales = "free")
dhfr %>%
ggplot(aes(Y)) +
geom_bar() +
facet_wrap(~Y, scales = "free")
skimed_data %>%
ggplot(aes(Y)) +
geom_bar() +
facet_wrap(~Y, scales = "free")
skimed_data %>%
ggplot(aes(~)) +
geom_bar() +
facet_wrap(~Y, scales = "free")
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
model.cv <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Species)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Species)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Y)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Y)
model.training.confusion
model.testing.confusion
model.cv.confusion
#Feature Importance
Importance <- varImp(model)
plot(Importance, top = 25)
#Feature Importance
Importance <- varImp(model)
plot(Importance, top = 25)
#Feature Importance
Importance <- varImp(model)
#Feature Importance
Importance <- varImp(model-[1])
#Feature Importance
Importance <- varImp(model[:2])
#Feature Importance
Importance <- varImp(model)
#Feature Importance
dhfs$y <- as.numeric(as.character(dhfs$Y))
#Feature Importance
dhfr$y <- as.numeric(as.character(dhfr$Y))
Importance <- varImp(model)
plot(Importance, top = 25)
#Feature Importance
dhfr$y <- as.character(dhfr$Y)
View(dhfr)
Importance <- varImp(model)
#Feature Importance
dhfr1 <- dhfr[1,]
#Feature Importance
dhfr1 <- -c(dhfr$Y)
#Feature Importance
dhfr1 <- subset(dhfr, select = -c(dhfr$Y)
remove(dhfr1)
#Feature Importance
dhfr1 <- subset(dhfr, select = -c(dhfr$Y)
#Feature Importance
dhfr1 <- subset(dhfr, select = -c(dhfr$Y)
#Feature Importance
dhfr1 <- subset(dhfr, select = -c(dhfr$Y)
#Feature Importance
dhfr1 <- subset(dhfr, select = -c(dhfr$Y))
dhfr1 <- subset(dhfr, select = -c(dhfr$Y))
dhfr1 <- subset(dhfr, select = -c(dhfr$Y))
dhfr1 <- dhfr[-c(1)]
Importance <- varImp(model[-c(1)])
#Load Dataset
dhfr <- read_csv("dhfr_data.csv")
trainingIndex <- createDataPartition(dhfr$Y, p = 0.8, list = FALSE) # create index for 80% of dataset
trainingSet <- dhfr[trainingIndex,] # Split dataset with index (80% of dataset used for training)
testingSet <- dhfr[-trainingIndex,] # Use remaining 20% for testing
featurePlot(x = trainingSet[,1:4],
y = trainingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainingSet[,1:4],
y = trainingSet$Y,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = testingSet[,1:4],
y = testingSet$Y,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
model.cv <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Y)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Y)
model.training.confusion
model.testing.confusion
model.cv.confusion
#dhfr1 <- dhfr[-c(1)]
Importance <- varImp(model)
#Load Dataset
dhfr <- read_csv("dhfr_data.csv")
#dhfr$Y <- as.factor(dhfr$Y)
summary(dhfr)
summary(dhfr$Y)
# check If NA values exist
sum(is.na(dhfr))
skimed_data <-dhfr %>%
group_by(Y) %>%
skim()
plot(dhfr$moe2D_zagreb, dhfr$moe2D_weinerPol, xlab = "2D Zagreb", ylab = "2D WeinerPol", col = dhfr$Y ) # red circle show activeity (Y)
# set seed
set.seed(100)
trainingIndex <- createDataPartition(dhfr$Y, p = 0.8, list = FALSE) # create index for 80% of dataset
trainingSet <- dhfr[trainingIndex,] # Split dataset with index (80% of dataset used for training)
testingSet <- dhfr[-trainingIndex,] # Use remaining 20% for testing
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
# Build CV model
model.cv <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Y)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Y)
model.training.confusion
model.testing.confusion
model.cv.confusion
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
dhfr$Y <- as.factor(dhfr$Y)
summary(dhfr)
summary(dhfr$Y)
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
# Build CV model
model.cv <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Y)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Y)
trainingIndex <- createDataPartition(dhfr$Y, p = 0.8, list = FALSE) # create index for 80% of dataset
trainingSet <- dhfr[trainingIndex,] # Split dataset with index (80% of dataset used for training)
testingSet <- dhfr[-trainingIndex,] # Use remaining 20% for testing
model <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
# Build CV model
model.cv <- train(Y ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Y)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Y)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Y)
model.training.confusion
model.testing.confusion
model.cv.confusion
#dhfr1 <- dhfr[-c(1)]
Importance <- varImp(model)
args(varImp)
?varImp
sum(is.na(dhfr))
# To achieve reproducible model; set the random seed number
set.seed(100)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(dhfr$Y, p=0.8, list = FALSE)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(dhfr$Y, p=0.8, list = FALSE)
#Load Dataset
dhfr <- read_csv("dhfr_data.csv")
sum(is.na(dhfr))
# To achieve reproducible model; set the random seed number
set.seed(100)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(dhfr$Y, p=0.8, list = FALSE)
TrainingSet <- dhfr[TrainingIndex,] # Training Set
TestingSet <- dhfr[-TrainingIndex,] # Test Set
# Build Training model
Model <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="none"),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Build CV model
Model.cv <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="cv", number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Apply model for prediction
Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set
Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set
Model.cv <-predict(Model.cv, TrainingSet) # Perform cross-validation
# Model performance (Displays confusion matrix and statistics)
Model.training.confusion <-confusionMatrix(Model.training, TrainingSet$Y)
Model.testing.confusion <-confusionMatrix(Model.testing, TestingSet$Y)
Model.cv.confusion <-confusionMatrix(Model.cv, TrainingSet$Y)
print(Model.training.confusion)
Model.cv.confusion <-confusionMatrix(Model.cv, TrainingSet$Y)
dhfr$Y <- as.factor(dhfr$Y)
# Build Training model
Model <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="none"),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Build CV model
Model.cv <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="cv", number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Apply model for prediction
Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set
Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set
Model.cv <-predict(Model.cv, TrainingSet) # Perform cross-validation
# Model performance (Displays confusion matrix and statistics)
Model.training.confusion <-confusionMatrix(Model.training, TrainingSet$Y)
Model.testing.confusion <-confusionMatrix(Model.testing, TestingSet$Y)
# Model performance (Displays confusion matrix and statistics)
Model.training.confusion <-confusionMatrix(Model.training, TrainingSet$Y)
Model.testing.confusion <-confusionMatrix(Model.testing, TestingSet$Y)
# Model performance (Displays confusion matrix and statistics)
Model.training.confusion <-confusionMatrix(Model.training, TrainingSet$Y)
#Load Dataset
dhfr <- read_csv("dhfr_data.csv")
dhfr$Y <- as.factor(dhfr$Y)
sum(is.na(dhfr))
# To achieve reproducible model; set the random seed number
set.seed(100)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(dhfr$Y, p=0.8, list = FALSE)
TrainingSet <- dhfr[TrainingIndex,] # Training Set
TestingSet <- dhfr[-TrainingIndex,] # Test Set
# Build Training model
Model <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="none"),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Build CV model
Model.cv <- train(Y ~ ., data = TrainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess=c("scale","center"),
trControl= trainControl(method="cv", number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
# Apply model for prediction
Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set
Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set
Model.cv <-predict(Model.cv, TrainingSet) # Perform cross-validation
# Model performance (Displays confusion matrix and statistics)
Model.training.confusion <-confusionMatrix(Model.training, TrainingSet$Y)
Model.testing.confusion <-confusionMatrix(Model.testing, TestingSet$Y)
Model.cv.confusion <-confusionMatrix(Model.cv, TrainingSet$Y)
print(Model.training.confusion)
print(Model.testing.confusion)
print(Model.cv.confusion)
# Feature importance
Importance <- varImp(Model)
